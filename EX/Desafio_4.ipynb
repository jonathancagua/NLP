{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathancagua/NLP/blob/main/EX/Desafio_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRS1_FwSREub"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# URL del dataset ConvAI2\n",
        "url = \"http://convai.io/data/summer_wild_evaluation_dialogs.json\"\n",
        "\n",
        "try:\n",
        "    # Descargar el dataset\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Lanza excepción si hubo error HTTP\n",
        "    convai2_json = response.json()\n",
        "except requests.exceptions.RequestException as e:\n",
        "    raise SystemExit(f\"Error al descargar el dataset: {e}\")\n",
        "except json.JSONDecodeError:\n",
        "    raise SystemExit(\"Error al decodificar el JSON recibido.\")\n",
        "\n",
        "# Extraer pares pregunta-respuesta\n",
        "questions, answers = [], []\n",
        "\n",
        "for dialog in convai2_json:\n",
        "    utterances = dialog.get('dialog', [])\n",
        "    for i in range(len(utterances) - 1):\n",
        "        q = utterances[i].get('text', '').strip()\n",
        "        a = utterances[i + 1].get('text', '').strip()\n",
        "        if q and a:  # Ignorar si alguno está vacío\n",
        "            questions.append(q)\n",
        "            answers.append(a)\n",
        "\n",
        "# Crear DataFrame con los primeros 15,000 pares\n",
        "df = pd.DataFrame({'question': questions, 'answer': answers})\n",
        "df = df.iloc[:15000].copy()\n",
        "\n",
        "# Vista previa\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N6dKV0wdR_st",
        "outputId": "8a53e05b-7843-4932-fc02-aa206120c556"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0           I love iphone! i just bought new iphone!   \n",
              "1     Thats good for you, i'm not very into new tech   \n",
              "2  I am a college student and i am a college student   \n",
              "3               I am go to gym and live on donations   \n",
              "4               I am a vegan and i am in the midwest   \n",
              "\n",
              "                                              answer  \n",
              "0     Thats good for you, i'm not very into new tech  \n",
              "1  I am a college student and i am a college student  \n",
              "2               I am go to gym and live on donations  \n",
              "3               I am a vegan and i am in the midwest  \n",
              "4  So vegan... i have dogs maybe i should told th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49dacccc-1484-456e-9247-27b61568ca20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love iphone! i just bought new iphone!</td>\n",
              "      <td>Thats good for you, i'm not very into new tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thats good for you, i'm not very into new tech</td>\n",
              "      <td>I am a college student and i am a college student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am a college student and i am a college student</td>\n",
              "      <td>I am go to gym and live on donations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am go to gym and live on donations</td>\n",
              "      <td>I am a vegan and i am in the midwest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am a vegan and i am in the midwest</td>\n",
              "      <td>So vegan... i have dogs maybe i should told th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49dacccc-1484-456e-9247-27b61568ca20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49dacccc-1484-456e-9247-27b61568ca20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49dacccc-1484-456e-9247-27b61568ca20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8623fa17-f50e-4c90-bb5c-f77816ec792d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8623fa17-f50e-4c90-bb5c-f77816ec792d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8623fa17-f50e-4c90-bb5c-f77816ec792d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15000,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10820,\n        \"samples\": [\n          \"Which sport?\",\n          \"I'm not sure.\",\n          \"So you like to run?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11110,\n        \"samples\": [\n          \"I like to drink a lot\",\n          \"The Westside Museum of Art is having a new exhibit of a masterpiece by Franz Biermann.\",\n          \"i have not heard of that .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV3QhjRVBaCY",
        "outputId": "5a43a710-effa-49b7-e7cc-f38d45840bc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gifuP1F8SIt3",
        "outputId": "88ac87b8-4482-44a7-b209-072fe272aebc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Diccionario ampliado de contracciones\n",
        "CONTRACTIONS = {\n",
        "    \"i'm\": \"i am\", \"you're\": \"you are\", \"he's\": \"he is\", \"she's\": \"she is\",\n",
        "    \"it's\": \"it is\", \"we're\": \"we are\", \"they're\": \"they are\", \"can't\": \"cannot\",\n",
        "    \"won't\": \"will not\", \"don't\": \"do not\", \"didn't\": \"did not\", \"i've\": \"i have\",\n",
        "    \"i'll\": \"i will\", \"you'll\": \"you will\", \"she'd\": \"she would\", \"should've\": \"should have\",\n",
        "    \"there's\": \"there is\", \"we'd\": \"we would\", \"they'll\": \"they will\", \"wasn't\": \"was not\",\n",
        "    \"isn't\": \"is not\", \"aren't\": \"are not\", \"couldn't\": \"could not\", \"wouldn't\": \"would not\",\n",
        "    \"hasn't\": \"has not\", \"hadn't\": \"had not\", \"we'll\": \"we will\", \"they'd\": \"they would\",\n",
        "    \"who's\": \"who is\", \"what's\": \"what is\", \"let's\": \"let us\", \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "# Expande contracciones en el texto\n",
        "def expand_contractions(text):\n",
        "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in CONTRACTIONS) + r')\\b')\n",
        "    return pattern.sub(lambda x: CONTRACTIONS[x.group()], text)\n",
        "\n",
        "# Función de limpieza completa\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Minusculizar\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text()  # Eliminar HTML\n",
        "    text = re.sub(r'http\\S+', '', text)  # Eliminar URLs\n",
        "    text = expand_contractions(text)  # Expandir contracciones\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Eliminar puntuación\n",
        "    text = re.sub(r'\\d+', '', text)  # Eliminar números\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalizar espacios\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)  # Limitar letras repetidas (coooool → coool)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remover caracteres no ASCII\n",
        "    text = re.sub(r'[\\u2600-\\u26FF\\u263a-\\U0001f645]', ' ', text)  # Remover emojis y símbolos Unicode\n",
        "    tokens = word_tokenize(text)  # Tokenizar\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Aplicar limpieza al DataFrame\n",
        "df['question_clean'] = df['question'].astype(str).apply(clean_text)\n",
        "df['answer_clean'] = df['answer'].astype(str).apply(clean_text)\n",
        "\n",
        "# Agregar tokens de inicio y fin de secuencia\n",
        "df['answer_clean'] = df['answer_clean'].apply(lambda x: '<sos> ' + x.strip() + ' <eos>')\n",
        "\n",
        "# Filtrado y limpieza final\n",
        "df = df.dropna(subset=['question_clean', 'answer_clean'])\n",
        "df = df[(df['question_clean'].str.strip() != '') & (df['answer_clean'].str.strip() != '')]\n",
        "df = df[df['question_clean'] != df['answer_clean']]\n",
        "df = df[df['answer_clean'].str.split().apply(len) > 3]\n",
        "df = df.drop_duplicates(subset=['question_clean', 'answer_clean'])\n",
        "\n",
        "# Vista previa\n",
        "print(f\"Total de pares tras limpieza: {len(df)}\")\n",
        "display(df[['question_clean', 'answer_clean']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "2CVjy7D0TBi1",
        "outputId": "78197c0d-bf47-40ce-8f7e-8b63c4551366"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de pares tras limpieza: 12647\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                      question_clean  \\\n",
              "0             i love iphone i just bought new iphone   \n",
              "1     thats good for you i am not very into new tech   \n",
              "2  i am a college student and i am a college student   \n",
              "3               i am go to gym and live on donations   \n",
              "4               i am a vegan and i am in the midwest   \n",
              "\n",
              "                                        answer_clean  \n",
              "0  <sos> thats good for you i am not very into ne...  \n",
              "1  <sos> i am a college student and i am a colleg...  \n",
              "2   <sos> i am go to gym and live on donations <eos>  \n",
              "3   <sos> i am a vegan and i am in the midwest <eos>  \n",
              "4  <sos> so vegan i have dogs maybe i should told...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6b22870-34ab-40ad-9f8b-6e3c423271e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_clean</th>\n",
              "      <th>answer_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i love iphone i just bought new iphone</td>\n",
              "      <td>&lt;sos&gt; thats good for you i am not very into ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thats good for you i am not very into new tech</td>\n",
              "      <td>&lt;sos&gt; i am a college student and i am a colleg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am a college student and i am a college student</td>\n",
              "      <td>&lt;sos&gt; i am go to gym and live on donations &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am go to gym and live on donations</td>\n",
              "      <td>&lt;sos&gt; i am a vegan and i am in the midwest &lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am a vegan and i am in the midwest</td>\n",
              "      <td>&lt;sos&gt; so vegan i have dogs maybe i should told...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6b22870-34ab-40ad-9f8b-6e3c423271e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6b22870-34ab-40ad-9f8b-6e3c423271e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6b22870-34ab-40ad-9f8b-6e3c423271e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0f2e0a02-221c-4021-8b6e-a84e71921b22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f2e0a02-221c-4021-8b6e-a84e71921b22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0f2e0a02-221c-4021-8b6e-a84e71921b22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['question_clean', 'answer_clean']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"thats good for you i am not very into new tech\",\n          \"i am a vegan and i am in the midwest\",\n          \"i am a college student and i am a college student\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<sos> i am a college student and i am a college student <eos>\",\n          \"<sos> so vegan i have dogs maybe i should told then that they may eat cheap salads insted of meat <eos>\",\n          \"<sos> i am go to gym and live on donations <eos>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Parámetros\n",
        "MAX_VOCAB_SIZE = 6000\n",
        "MAX_SEQ_LENGTH = 25\n",
        "\n",
        "# Tokenizadores\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=True, oov_token='<unk>')\n",
        "tokenizer_inputs.fit_on_texts(df['question_clean'])\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(df['question_clean'])\n",
        "\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='', lower=True, oov_token='<unk>')\n",
        "tokenizer_outputs.fit_on_texts(df['answer_clean'])\n",
        "output_sequences = tokenizer_outputs.texts_to_sequences(df['answer_clean'])\n",
        "\n",
        "# Diccionarios de vocabulario\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "\n",
        "# Asegurarse de respetar el vocabulario limitado\n",
        "num_words_output = min(MAX_VOCAB_SIZE, len(word2idx_outputs) + 1)\n",
        "\n",
        "# Longitudes máximas de secuencia\n",
        "max_input_len = min(MAX_SEQ_LENGTH, max(len(seq) for seq in input_sequences))\n",
        "max_output_len = min(MAX_SEQ_LENGTH, max(len(seq) for seq in output_sequences))\n",
        "\n",
        "# Padding (relleno con ceros al final)\n",
        "encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
        "decoder_input_sequences = pad_sequences(output_sequences, maxlen=max_output_len, padding='post')\n",
        "\n",
        "# Targets del decoder (one-hot desplazados)\n",
        "decoder_targets = np.zeros((len(decoder_input_sequences), max_output_len, num_words_output), dtype='float32')\n",
        "\n",
        "for i, seq in enumerate(decoder_input_sequences):\n",
        "    for t in range(1, len(seq)):\n",
        "        word_idx = seq[t]\n",
        "        if word_idx < num_words_output:\n",
        "            decoder_targets[i, t - 1, word_idx] = 1.0\n",
        "\n",
        "# Prints informativos\n",
        "print(f\"Total de pares pregunta-respuesta: {len(df)}\")\n",
        "print(f\"Vocabulario input: {min(len(word2idx_inputs), MAX_VOCAB_SIZE)}\")\n",
        "print(f\"Vocabulario output: {num_words_output}\")\n",
        "print(f\"Longitud máxima input: {max_input_len}\")\n",
        "print(f\"Longitud máxima output: {max_output_len}\")\n",
        "print(f\"Shape de decoder_targets: {decoder_targets.shape}\")\n",
        "\n",
        "# Ejemplo ilustrativo\n",
        "idx = 0\n",
        "print(\"\\n🔎 Ejemplo:\")\n",
        "print(f\"Pregunta original: {df['question_clean'].iloc[idx]}\")\n",
        "print(f\"Secuencia tokenizada: {input_sequences[idx]}\")\n",
        "print(f\"Secuencia padded: {encoder_input_sequences[idx]}\")\n",
        "print(f\"Respuesta tokenizada: {output_sequences[idx]}\")\n",
        "print(f\"Respuesta padded: {decoder_input_sequences[idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5i_gfBRTNJr",
        "outputId": "ecb7681b-75e1-48b7-dbc5-03b6b983db4f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de pares pregunta-respuesta: 12647\n",
            "Vocabulario input: 4042\n",
            "Vocabulario output: 4167\n",
            "Longitud máxima input: 25\n",
            "Longitud máxima output: 25\n",
            "Shape de decoder_targets: (12647, 25, 4167)\n",
            "\n",
            "🔎 Ejemplo:\n",
            "Pregunta original: i love iphone i just bought new iphone\n",
            "Secuencia tokenizada: [2, 21, 854, 2, 39, 739, 145, 854]\n",
            "Secuencia padded: [  2  21 854   2  39 739 145 854   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "Respuesta tokenizada: [2, 54, 28, 27, 5, 4, 6, 10, 53, 231, 154, 2231, 3]\n",
            "Respuesta padded: [   2   54   28   27    5    4    6   10   53  231  154 2231    3    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas requests numpy==1.26.4 gensim==4.3.3 nltk tensorflow==2.16.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoleajnGULo1",
        "outputId": "501a440b-7e92-4c09-ba63-82a4e5a9b6dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tensorflow==2.16.1 in /usr/local/lib/python3.11/dist-packages (2.16.1)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.3) (7.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import gensim.downloader as api\n",
        "import gensim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Parámetros\n",
        "EMBEDDING_MODEL = 'fasttext-wiki-news-subwords-300'\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "def load_fasttext_model():\n",
        "    print(\"Cargando modelo FastText...\")\n",
        "    try:\n",
        "        return api.load(EMBEDDING_MODEL)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar FastText: {e}\")\n",
        "        return None\n",
        "\n",
        "def build_embedding_matrix(tokenizer, embedding_model, vocab_size, embedding_dim):\n",
        "    word_index = tokenizer.word_index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    found = 0\n",
        "    missing_words = []\n",
        "\n",
        "    print(\"Generando matriz de embeddings...\")\n",
        "    for word, i in tqdm(word_index.items(), total=len(word_index), desc=\"Procesando palabras\"):\n",
        "        if i >= vocab_size:\n",
        "            continue\n",
        "        if word in embedding_model:\n",
        "            embedding_matrix[i] = embedding_model[word]\n",
        "            found += 1\n",
        "        else:\n",
        "            missing_words.append(word)\n",
        "\n",
        "    print(f\"\\n Palabras encontradas: {found}/{len(word_index)}\")\n",
        "    print(f\"Palabras faltantes: {len(missing_words)} (ej: {missing_words[:10]})\")\n",
        "    print(f\"Dimensión de la matriz: {embedding_matrix.shape}\")\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "# Ejecución\n",
        "fasttext_model = load_fasttext_model()\n",
        "embedding_matrix = build_embedding_matrix(tokenizer_inputs, fasttext_model, MAX_VOCAB_SIZE, EMBEDDING_DIM)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feSbcZ9FTkRr",
        "outputId": "16514f2f-c2d2-4d9e-daab-a950876e431d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando modelo FastText...\n",
            "Generando matriz de embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando palabras: 100%|██████████| 4042/4042 [00:00<00:00, 209306.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Palabras encontradas: 3731/4042\n",
            "Palabras faltantes: 311 (ej: ['<unk>', 'convai', 'whazzup', 'buongiorno', '_', 'poyou', 'zitah', 'orhun', 'wontice', 'hesnt'])\n",
            "Dimensión de la matriz: (6000, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modelo Seq2Seq con atención Luong (dot-product)"
      ],
      "metadata": {
        "id": "qchrbxGYVlPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dot, Activation, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Parámetros\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_len,))\n",
        "encoder_embedding = Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM,\n",
        "                              weights=[embedding_matrix],\n",
        "                              input_length=max_input_len,\n",
        "                              trainable=False)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_output_len,))\n",
        "decoder_embedding_layer = Embedding(num_words_output, latent_dim)\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Atención (Luong: dot product entre encoder_outputs y decoder_outputs)\n",
        "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])         # (batch, dec_seq, enc_seq)\n",
        "attention = Activation('softmax')(attention)                             # softmax sobre el encoder sequence\n",
        "context = Dot(axes=[2,1])([attention, encoder_outputs])                 # contexto ponderado\n",
        "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
        "\n",
        "# Output final\n",
        "output = Dense(256, activation='tanh')(decoder_combined_context)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(output)\n",
        "\n",
        "# Modelo final con atención\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compilar\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "_UcEC5IIVsG4",
        "outputId": "68cc7be9-6c46-4e45-afc7-359199ea8a64"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,800,000\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,066,752\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_8 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dot_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_9 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dot_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m131,328\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m4167\u001b[0m)  │  \u001b[38;5;34m1,070,919\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,000</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,066,752</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4167</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,070,919</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,164,679\u001b[0m (19.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,164,679</span> (19.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,364,679\u001b[0m (12.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,364,679</span> (12.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,800,000\u001b[0m (6.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,000</span> (6.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Parámetros de entrenamiento\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "MODEL_PATH = 'best_model.keras'\n",
        "\n",
        "# Callback: detener si no mejora val_loss en N épocas\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Callback: guardar el mejor modelo basado en val_loss\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=MODEL_PATH,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cr7BTCwXWmt",
        "outputId": "f1c240d9-a6ec-4dfd-b169-a2864c40cfb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step - accuracy: 0.6453 - loss: 3.1649\n",
            "Epoch 1: val_loss improved from inf to 1.75503, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 993ms/step - accuracy: 0.6455 - loss: 3.1589 - val_accuracy: 0.7178 - val_loss: 1.7550\n",
            "Epoch 2/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.7259 - loss: 1.7033\n",
            "Epoch 2: val_loss improved from 1.75503 to 1.58937, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 965ms/step - accuracy: 0.7260 - loss: 1.7030 - val_accuracy: 0.7509 - val_loss: 1.5894\n",
            "Epoch 3/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.7496 - loss: 1.5334\n",
            "Epoch 3: val_loss improved from 1.58937 to 1.48444, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 980ms/step - accuracy: 0.7497 - loss: 1.5332 - val_accuracy: 0.7632 - val_loss: 1.4844\n",
            "Epoch 4/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.7658 - loss: 1.4017\n",
            "Epoch 4: val_loss improved from 1.48444 to 1.42940, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 971ms/step - accuracy: 0.7658 - loss: 1.4016 - val_accuracy: 0.7699 - val_loss: 1.4294\n",
            "Epoch 5/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.7750 - loss: 1.3213\n",
            "Epoch 5: val_loss improved from 1.42940 to 1.38000, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 980ms/step - accuracy: 0.7750 - loss: 1.3212 - val_accuracy: 0.7760 - val_loss: 1.3800\n",
            "Epoch 6/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.7839 - loss: 1.2446\n",
            "Epoch 6: val_loss improved from 1.38000 to 1.35329, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 986ms/step - accuracy: 0.7839 - loss: 1.2445 - val_accuracy: 0.7799 - val_loss: 1.3533\n",
            "Epoch 7/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855ms/step - accuracy: 0.7857 - loss: 1.2043\n",
            "Epoch 7: val_loss improved from 1.35329 to 1.32265, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 986ms/step - accuracy: 0.7857 - loss: 1.2042 - val_accuracy: 0.7828 - val_loss: 1.3226\n",
            "Epoch 8/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - accuracy: 0.7965 - loss: 1.1218\n",
            "Epoch 8: val_loss improved from 1.32265 to 1.30562, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 983ms/step - accuracy: 0.7965 - loss: 1.1218 - val_accuracy: 0.7833 - val_loss: 1.3056\n",
            "Epoch 9/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854ms/step - accuracy: 0.7999 - loss: 1.0801\n",
            "Epoch 9: val_loss improved from 1.30562 to 1.28700, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 985ms/step - accuracy: 0.7999 - loss: 1.0801 - val_accuracy: 0.7858 - val_loss: 1.2870\n",
            "Epoch 10/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849ms/step - accuracy: 0.8027 - loss: 1.0467\n",
            "Epoch 10: val_loss improved from 1.28700 to 1.28194, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 980ms/step - accuracy: 0.8027 - loss: 1.0467 - val_accuracy: 0.7878 - val_loss: 1.2819\n",
            "Epoch 11/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871ms/step - accuracy: 0.8082 - loss: 1.0047\n",
            "Epoch 11: val_loss improved from 1.28194 to 1.27280, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.8082 - loss: 1.0047 - val_accuracy: 0.7902 - val_loss: 1.2728\n",
            "Epoch 12/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.8110 - loss: 0.9751\n",
            "Epoch 12: val_loss improved from 1.27280 to 1.26265, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 995ms/step - accuracy: 0.8110 - loss: 0.9751 - val_accuracy: 0.7918 - val_loss: 1.2627\n",
            "Epoch 13/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.8151 - loss: 0.9409\n",
            "Epoch 13: val_loss improved from 1.26265 to 1.25913, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 996ms/step - accuracy: 0.8151 - loss: 0.9409 - val_accuracy: 0.7936 - val_loss: 1.2591\n",
            "Epoch 14/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866ms/step - accuracy: 0.8176 - loss: 0.9180\n",
            "Epoch 14: val_loss did not improve from 1.25913\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 995ms/step - accuracy: 0.8176 - loss: 0.9180 - val_accuracy: 0.7926 - val_loss: 1.2625\n",
            "Epoch 15/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872ms/step - accuracy: 0.8232 - loss: 0.8754\n",
            "Epoch 15: val_loss improved from 1.25913 to 1.25525, saving model to best_model.keras\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 1s/step - accuracy: 0.8232 - loss: 0.8755 - val_accuracy: 0.7948 - val_loss: 1.2553\n",
            "Epoch 16/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870ms/step - accuracy: 0.8257 - loss: 0.8539\n",
            "Epoch 16: val_loss did not improve from 1.25525\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1000ms/step - accuracy: 0.8257 - loss: 0.8539 - val_accuracy: 0.7950 - val_loss: 1.2606\n",
            "Epoch 17/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859ms/step - accuracy: 0.8269 - loss: 0.8433\n",
            "Epoch 17: val_loss did not improve from 1.25525\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 989ms/step - accuracy: 0.8269 - loss: 0.8433 - val_accuracy: 0.7953 - val_loss: 1.2617\n",
            "Epoch 18/30\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861ms/step - accuracy: 0.8292 - loss: 0.8249\n",
            "Epoch 18: val_loss did not improve from 1.25525\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 941ms/step - accuracy: 0.8292 - loss: 0.8248 - val_accuracy: 0.7957 - val_loss: 1.2628\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Descargar el modelo guardado\n",
        "files.download(MODEL_PATH)"
      ],
      "metadata": {
        "id": "toWlGArcdK6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "aeadc42a-df10-48f9-cd12-1cce166b048c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c8394c7b-8a71-4376-a530-bae55130807c\", \"best_model.keras\", 47636451)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "\n",
        "# Subir archivos desde tu computadora\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "vFpn04lvdau8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencia"
      ],
      "metadata": {
        "id": "9ecMuluKYjv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])"
      ],
      "metadata": {
        "id": "iss20PHI5y8m"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "decoder_input_single = Input(shape=(1,))\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "encoder_outputs_input = Input(shape=(max_input_len, latent_dim))\n",
        "\n",
        "decoder_embedding_inf = decoder_embedding_layer(decoder_input_single)\n",
        "\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_embedding_inf,\n",
        "    initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        ")\n",
        "\n",
        "\n",
        "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "attention = Activation('softmax')(attention)\n",
        "context = Dot(axes=[2, 1])([attention, encoder_outputs_input])\n",
        "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
        "\n",
        "# Salida densa\n",
        "decoder_tanh = Dense(256, activation='tanh')(decoder_combined_context)\n",
        "decoder_output_probs = decoder_dense(decoder_tanh)\n",
        "\n",
        "# Modelo final de inferencia\n",
        "decoder_model = Model(\n",
        "    [decoder_input_single, decoder_state_input_h, decoder_state_input_c, encoder_outputs_input],\n",
        "    [decoder_outputs, state_h, state_c]\n",
        ")"
      ],
      "metadata": {
        "id": "FY22vq_e5300"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word2idx_outputs = {idx: word for word, idx in word2idx_outputs.items()}\n"
      ],
      "metadata": {
        "id": "jJvr7WCVE1fd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def decode_sequence_beam_super(input_seq, beam_width=3, max_repeat=3, min_prob=1e-6, length_penalty_alpha=0.6):\n",
        "    \"\"\"\n",
        "    Decodifica una secuencia de entrada utilizando búsqueda Beam Search con penalización por longitud y control de repeticiones.\n",
        "\n",
        "    Args:\n",
        "        input_seq (np.array): Secuencia de entrada para el codificador (encoder).\n",
        "        beam_width (int): Número de caminos alternativos a mantener en cada paso de decodificación.\n",
        "        max_repeat (int): Número máximo de veces que una palabra puede repetirse antes de ser eliminada.\n",
        "        min_prob (float): Probabilidad mínima permitida para considerar una predicción.\n",
        "        length_penalty_alpha (float): Exponente de penalización por longitud. Un valor mayor favorece secuencias más largas.\n",
        "\n",
        "    Returns:\n",
        "        str: Secuencia de palabras decodificada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ejecuta el codificador y obtiene la salida junto con los estados iniciales\n",
        "    enc_outs, h, c = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Inicializa la lista de secuencias con el token de inicio (<sos>)\n",
        "    sequences = [([word2idx_outputs['<sos>']], 0.0, h, c)]\n",
        "\n",
        "    # Itera hasta alcanzar la longitud máxima de salida permitida\n",
        "    for _ in range(max_output_len):\n",
        "        all_candidates = []\n",
        "\n",
        "        # Evalúa cada secuencia actual en el beam\n",
        "        for seq, score, h, c in sequences:\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = seq[-1]  # Última palabra decodificada\n",
        "\n",
        "            # Predice el siguiente token y actualiza los estados\n",
        "            output_tokens, h_new, c_new = decoder_model.predict([target_seq, h, c, enc_outs], verbose=0)\n",
        "            output_probs = output_tokens[0, -1, :]  # Distribución de probabilidad para el siguiente token\n",
        "\n",
        "            # Selecciona los índices con mayor probabilidad (beam search)\n",
        "            top_indices = output_probs.argsort()[-beam_width:][::-1]\n",
        "\n",
        "            # Genera nuevos candidatos a partir de los mejores tokens\n",
        "            for idx in top_indices:\n",
        "                if idx not in reverse_word2idx_outputs:\n",
        "                    continue\n",
        "                word = reverse_word2idx_outputs[idx]\n",
        "                prob = output_probs[idx]\n",
        "\n",
        "                if prob < min_prob:\n",
        "                    continue  # Descarta tokens poco probables\n",
        "\n",
        "                new_seq = seq + [idx]\n",
        "\n",
        "                # Si se genera el token de fin (<eos>), se decodifica la secuencia actual\n",
        "                if word == '<eos>':\n",
        "                    decoded = [reverse_word2idx_outputs.get(i, \"<UNK>\") for i in new_seq[1:-1]]  # omite <sos> y <eos>\n",
        "                    return ' '.join(decoded)\n",
        "\n",
        "                # Calcula penalización por longitud (para evitar secuencias muy cortas)\n",
        "                length_penalty = ((5 + len(new_seq)) / 6) ** length_penalty_alpha\n",
        "                candidate_score = (score - np.log(prob + 1e-10)) / length_penalty\n",
        "\n",
        "                all_candidates.append((new_seq, candidate_score, h_new, c_new))\n",
        "\n",
        "        if not all_candidates:\n",
        "            break  # No hay más candidatos válidos\n",
        "\n",
        "        # Selecciona los beam_width mejores candidatos\n",
        "        sequences = sorted(all_candidates, key=lambda tup: tup[1])[:beam_width]\n",
        "\n",
        "    # Si no se encuentra <eos>, se toma la mejor secuencia final\n",
        "    final_sequence = sequences[0][0][1:]  # omite el <sos>\n",
        "    decoded_words = [reverse_word2idx_outputs.get(i, \"<UNK>\") for i in final_sequence]\n",
        "\n",
        "    # Elimina repeticiones excesivas de palabras\n",
        "    word_counts = Counter(decoded_words)\n",
        "    most_common_word, count = word_counts.most_common(1)[0]\n",
        "    if count > max_repeat:\n",
        "        decoded_words = list(dict.fromkeys(decoded_words))  # preserva el orden\n",
        "\n",
        "    # Elimina triples consecutivos (ej: \"hola hola hola\")\n",
        "    cleaned = []\n",
        "    for w in decoded_words:\n",
        "        if len(cleaned) < 2 or not (w == cleaned[-1] == cleaned[-2]):\n",
        "            cleaned.append(w)\n",
        "\n",
        "    return ' '.join(cleaned)\n"
      ],
      "metadata": {
        "id": "cXEjgVLTFoDe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUSpPBrXaHin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_beam_super(question):\n",
        "    question_clean = clean_text(question)\n",
        "    seq = tokenizer_inputs.texts_to_sequences([question_clean])\n",
        "    pad_seq = pad_sequences(seq, maxlen=max_input_len, padding='post')\n",
        "    return decode_sequence_beam_super(pad_seq)\n",
        "\n",
        "# Probar\n",
        "test_questions = [\n",
        "    \"Do you like tv or radio?\",\n",
        "    \"Why did you choose to become a vegan?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"Question: {q}\")\n",
        "    print(f\"Answer: {answer_question_beam_super(q)}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc1frMgrF_sb",
        "outputId": "f0f7d78a-bac2-4ea9-ea76-2c98bd1524f5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧍 Question: Do you like tv or radio?\n",
            "🤖 Answer: tv\n",
            "\n",
            "🧍 Question: Why did you choose to become a vegan?\n",
            "🤖 Answer: good end at see drive text gym living little\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}